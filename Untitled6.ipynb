{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7g/7qkhNx8oabpB8i2lRe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deanhynes1/ARC/blob/master/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZIyOZJtI62S3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "790bccf2-6247-44cb-8f70-0d0d4b97cd70"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'steel.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-153d81809b71>\u001b[0m in \u001b[0;36m<cell line: 142>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#execute only if run as a script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-153d81809b71>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mCalls\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mregression\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     '''\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mML3_Regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#execute only if run as a script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-153d81809b71>\u001b[0m in \u001b[0;36mML3_Regression\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mML3_Regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepareData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m#call linar regression and svm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-153d81809b71>\u001b[0m in \u001b[0;36mprepareData\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepareData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#read the csv and scale the data+ add feature+targets,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"steel.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\s+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# tab seperated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m  \u001b[0;31m# Create the Scaler object##############################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'steel.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "import numpy as np\n",
        "from scipy import stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report #TO OUTPUT REPORT\n",
        "from sklearn.model_selection import KFold,cross_val_score,StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_selection import RFE\n",
        "import statsmodels.api as sm\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "def ML3_Regression():\n",
        "    X_train, X_test, y_train, y_test,targets,features,dataset = prepareData()\n",
        "    #call linar regression and svm.\n",
        "    linearRegression(features,targets,X_train, X_test, y_train, y_test)\n",
        "    SVM(dataset)#\n",
        "\n",
        "\n",
        "def plotModel(target, input):# used to check each feature againts the target\n",
        "    plt.scatter(target, input,color='green')\n",
        "    plt.plot([-1, 2], [-1, 2], '--k')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def prepareData():#read the csv and scale the data+ add feature+targets,\n",
        "    filename = \"steel.csv\"\n",
        "    dataset = pd.read_csv(filename,sep='\\s+')# tab seperated\n",
        " # Create the Scaler object##############################################\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    # Fit data on the scaler object\n",
        "    dataset = scaler.fit_transform(dataset)\n",
        "    dataset  = pd.DataFrame(dataset)\n",
        "\n",
        "    dataset.columns =['normalising_temperature','tempering_temperature', 'sample_id', 'percent_silicon', 'percent_chromium', 'manufacture_year', 'percent_copper', 'percent_nickel','percent_sulphur','percent_carbon','percent_manganese','tensile_strength']\n",
        "    #Features ranking:[       4                       5                     6            1                  3                     7                  1                1                   1                1                   2]\n",
        "    #Features to pic:[            True                True                 True               True        False                False                False              False            False             True                 True\n",
        "    ## Split the data into features and target\n",
        "    #do we need sample, manufacture_year,normalising_temperature',\n",
        "\n",
        "    #thisYear = 2019\n",
        "    #dataset['manufacture_year'] = thisYear - dataset['manufacture_year']\n",
        "    #print(dataset[ 'sample'])\n",
        "    print(\"------------------------------------------\")\n",
        "    '''\n",
        "    ##should all give false to say no data is missing, which it does.\n",
        "    print(pd.isnull(dataset).any())# no missing value check.\n",
        "    print(\"------------------------------------------\")\n",
        "    '''\n",
        "    targets = dataset[\"tensile_strength\"]# id the target\n",
        "    #features = dataset.drop(\"tensile_strength\", axis=1)   # Drop the variety name since this is our target\n",
        "    #features = dataset.drop(['tensile_strength','percent_manganese','tempering_temperature','percent_sulphur'], axis=1)\n",
        "    features = dataset.drop(['tensile_strength','percent_chromium','manufacture_year','percent_copper','percent_nickel','percent_sulphur'], axis=1)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, random_state=1) # 70% training and 20% test\n",
        "    #dataset.columns =['normalising_temperature','tempering_temperature', 'sample_id', 'percent_silicon', 'percent_chromium', 'manufacture_year', 'percent_copper', 'percent_nickel','percent_sulphur','percent_carbon','percent_manganese','tensile_strength']\n",
        "   #                            l                          nl                   wl           wl               wl                   wl                 wl                 wl               nl              wl                nl\n",
        "          #'percent_chromium','manufacture_year','percent_copper','percent_nickel','percent_sulphur'], axis=1)\n",
        "\n",
        "    #plotModel(targets, dataset['percent_manganese'])\n",
        "    return X_train, X_test, y_train, y_test,targets,features,dataset\n",
        "#linearRegression model\n",
        "def linearRegression(features, targets,X_train, X_test, y_train, y_test):\n",
        "    regression1 = LinearRegression(n_jobs=-1)# multi v. linear regressor\n",
        "    ##SELECT TOP 3 FEATUES TO USE.\n",
        "    #print(features['manufacture_year'])\n",
        "\n",
        "    rfe = RFE(regression1 ,6)#check best features of the data.\n",
        "    FIT = rfe.fit(X_train, y_train)\n",
        "    #print('Num Features:%s'%(FIT.n_features_))\n",
        "    #print(\"Features to pic:%s\"%(FIT.support_))\n",
        "    #Train classifier\n",
        "    regression1.fit(X_train, y_train)\n",
        "    predicted = regression1.predict(X_test)\n",
        "    expected = y_test\n",
        "    r_score = r2_score(y_test,predicted)\n",
        "    adr_r_score = 1 - (1-r_score)*(len(features)-1)/(len(features)-(features.shape[1]-1)-1)\n",
        "    mse = mean_squared_error(y_test,predicted)\n",
        "    #now do 10 fold validation#########################################################################\n",
        "    kfold1 = KFold(n_splits=10, random_state=100)\n",
        "    results_kfold1 = cross_val_score(regression1,X_test,y_test, cv=kfold1)\n",
        "    print('linearRegression run::')\n",
        "    #print(\"Training set accuracy:,{:.2f}\".format(regression1.score(X_train,y_train)))\n",
        "    print(\"Accuracy for 10 fold validation for Linear Regressor: %.2f%%\" % (results_kfold1.mean()*100.0))\n",
        "    print(\"R2 score for Linear Regression:\",r_score )\n",
        "    print(\"Adjusted Rscore for Linear regressor:\",adr_r_score)\n",
        "    print(\"LR score:\", regression1.score(X_test,y_test))\n",
        "    print(\"RMSE score for Linear regressor:\",sqrt(mse))\n",
        "\n",
        "    print(\"--------------------------------------------------------------\" )\n",
        "#svm model\n",
        "def SVM(dataset):\n",
        "    #manually check kernels\n",
        "    #reg4 = SVR(kernel='linear')\n",
        "    reg4 = SVR(gamma = 'auto',kernel='rbf',epsilon=.05)\n",
        "    #reg4 = SVR(gamma = 'auto',C=100,kernel='linear')\n",
        "    #reg4 = SVR(gamma = 'auto',kernel='poly',C=100,degree=3,epsilon=.1,coef0=1)\n",
        "    dataset = dataset[(np.abs(st.zscore(dataset)<2)).all(axis=1)]\n",
        "    targets = dataset[\"tensile_strength\"]# id the target    #features = dataset.drop(\"tensile_strength\", axis=1)   # Drop the variety name since this is our target    #features = dataset.drop(['tensile_strength','percent_manganese','tempering_temperature','percent_sulphur'], axis=1)\n",
        "    features = dataset.drop(['tensile_strength','percent_chromium','manufacture_year','percent_copper','percent_nickel','percent_sulphur'], axis=1)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, random_state=1)\n",
        "    reg4.fit(X_train,y_train)\n",
        "    y_pred = reg4.predict(X_test)\n",
        "    y_cv = cross_val_predict(reg4,X_test,y_test,cv=10)\n",
        "\n",
        "    r_score = r2_score(y_test,y_cv)\n",
        "    adr_r_score = 1 - (1-r_score)*(len(features)-1)/(len(features)-(features.shape[1]-1)-1)\n",
        "    mse = mean_squared_error(y_test,y_cv)\n",
        "    kfold2 = KFold(n_splits=10, random_state=100)\n",
        "    results_kfold3 = cross_val_score(reg4, features, targets, cv=kfold2)\n",
        "    print('SVM regression run::')\n",
        "    print(\"Accuracy for 10 fold validation on SVM Regressor: %.2f%%\" % (results_kfold3.mean()*100.0))\n",
        "    print(\"R2 score for SVM Regressor\",r_score)\n",
        "    print(\"LR score\", reg4.score(X_test,y_test))\n",
        "    print(\"Adjusted Rscore for SVM Regressor\",adr_r_score)\n",
        "    print(\"RMSE score for SVM Regressor\",sqrt(mse))\n",
        "    #print(\"Accuracy for 10 fold validation for SVM: %.2f%%\" % (results_kfold4.mean()*100.0))\n",
        "\n",
        "    #print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "\n",
        "def main():\n",
        "    '''\n",
        "    function def::\n",
        "    Calls the regression algorithms.\n",
        "    '''\n",
        "    ML3_Regression()\n",
        "\n",
        "if __name__==\"__main__\":#execute only if run as a script\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TbwgL3d1YvAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "GzU8TY7gW6uw"
      }
    }
  ]
}